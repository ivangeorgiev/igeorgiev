<!DOCTYPE html>
<html lang="">
<head>
	<meta charset="utf-8" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />

	<!-- Use the .htaccess and remove these lines to avoid edge case issues.
		 More info: h5bp.com/i/378 -->
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

	<!-- Our site title and description -->
	<title>Apache Spark Basics - Square Numbers | Ivan Georgiev</title>
	<meta name="description" content="Professional IT consulting. Proven Data Management expertise. Data integration with DataStage, Hadoop, Hive, Spark, Impala and more. Analytical, Business Intelligence and Data Science solutons." />
	<meta name="keywords" content="hadoop, bigdata, bigdata, spark, apache spark, tutorial" />
	<meta name="author" content="Ivan Georgiev" />

	<!-- Output DocPad produced meta elements -->
	<meta name="generator" content="DocPad v6.78.4" />

	<!-- Mobile viewport optimized: h5bp.com/viewport -->
	<meta name="viewport" content="width=device-width" />

	<!-- Icons -->
		<link rel="shortcut icon" href="images/icons/favicon.ico">
		<link rel="apple-touch-icon-precomposed" sizes="144x144" href="images/icons/apple-touch-icon-144-precomposed.png">
		<link rel="apple-touch-icon-precomposed" sizes="114x114" href="images/icons/apple-touch-icon-114-precomposed.png">
		<link rel="apple-touch-icon-precomposed" sizes="72x72" href="images/icons/apple-touch-icon-72-precomposed.png">
		<link rel="apple-touch-icon-precomposed" href="images/icons/apple-touch-icon-57-precomposed.png">

	<!-- Shims: IE6-8 support of HTML5 elements -->
	<!--[if lt IE 9]>
		<script async src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<!-- Styles -->
	<link  rel="stylesheet" href="/ext/bootstrap/css/bootstrap.css" /><link  rel="stylesheet" href="/ext/highlight.js/src/styles/default.css" /><link  rel="stylesheet" href="/css/style.css" />
</head>
<body>
    <nav class="navbar navbar-inverse">
      <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Ivan Georgiev</a>
        </div>
        
        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                
                  
                    <li
                        typeof="sioc:Page"
                        about="/index.html"
                        class=""
                    >
                        <a href="/index.html" property="dc:title"><span class="glyphicon glyphicon-home"></span>
                            Home
                        </a>
                    </li>
                  
                
                  
                
                  
                    <li
                        typeof="sioc:Page"
                        about="/blog.html"
                        class=""
                    >
                        <a href="/blog.html" property="dc:title"><span class="glyphicon glyphicon-edit"></span>
                            IT Blog
                        </a>
                    </li>
                  
                
                  
                
                  
                    <li
                        typeof="sioc:Page"
                        about="/contact.html"
                        class=""
                    >
                        <a href="/contact.html" property="dc:title"><span class="glyphicon glyphicon-envelope"></span>
                            Contact me
                        </a>
                    </li>
                  
                
                  
                
                  
                
            </ul>
        </div><!--/.navbar-collapse -->

        </div><!--/.container -->
    </nav>
    

	<!-- Content -->
	<div class="container">
		<!-- Content -->
		<section id="content" class="content">
			<article id="post" class="post">
	<h1>Apache Spark Basics - Square Numbers</h1>
	<div class="post-content"><p>This is the first example in the Apache Spark Basics. In this example, we will
  use Spark to compute the squares of the first 10 integer numbers.</p>

<p>I will assume you have installed Spark in either local or Yarn cluster manager mode.
If you do not have Spark installed, I suggest that you go to <a href="http://hortonworks.com/">Hortonworks</a> and download
the HDP Sandbox virtual machine. Similarly you can download and run 
  <a href="http://www.cloudera.com/">Cloudera's</a> Quick Start virtual machine.
  Installing Spark on a local machine is easy , but tricky. In future sessions I will show you how to install Spark on a local machine, running Standalone Scheduler.
</p>

<h3>Interactive Spark Execution with pySpark</h3>

<p><code>pySpark</code> is a Spark's interactive console for executing Python scripts.
  For those of you who are used to using Python console, windows command prompt or 
  Linux console, the concept of the Spark console should be familiar.</p>

<p>pySpark console is a convinient way for doing ad-hoc analytics and explore Spark's functionality.
Later I will show you how you can make things even better connecting pySpark to 
IPython notebook. For now let's keep things simple.</p>

<p>Start the <code>pySpark</code> console by executing the following command at the
command promtp:</p>

<pre class="highlight"><code class="hljs bash">$ pyspark</code></pre>

<p>Spark will start and display the prompt <code>>>></code>. Here is how it looks on my
machine. I use local Spark on a Windows machine.</p>

<pre class="highlight"><code class="hljs applescript">Python <span class="hljs-number">2.7</span><span class="hljs-number">.10</span> (default, May <span class="hljs-number">23</span> <span class="hljs-number">2015</span>, <span class="hljs-number">09</span>:<span class="hljs-number">44</span>:<span class="hljs-number">00</span>) [MSC v<span class="hljs-number">.1500</span> <span class="hljs-number">64</span> bit (AMD64)] <span class="hljs-function_start"><span class="hljs-keyword">on</span></span> win32
Type <span class="hljs-string">"help"</span>, <span class="hljs-string">"copyright"</span>, <span class="hljs-string">"credits"</span> <span class="hljs-keyword">or</span> <span class="hljs-string">"license"</span> <span class="hljs-keyword">for</span> more information.
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">13</span>:<span class="hljs-number">19</span>:<span class="hljs-number">11</span> WARN NativeCodeLoader: Unable <span class="hljs-keyword">to</span> load native-hadoop library <span class="hljs-keyword">for</span> your platform... using builtin-java classes <span class="hljs-keyword">where</span> applicable
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">13</span>:<span class="hljs-number">19</span>:<span class="hljs-number">13</span> WARN Utils: Service 'SparkUI' could <span class="hljs-keyword">not</span> bind <span class="hljs-function_start"><span class="hljs-keyword">on</span></span> port <span class="hljs-number">4040.</span> Attempting port <span class="hljs-number">4041.</span>
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">13</span>:<span class="hljs-number">19</span>:<span class="hljs-number">13</span> WARN MetricsSystem: Using default <span class="hljs-property">name</span> DAGScheduler <span class="hljs-keyword">for</span> source because spark.app.<span class="hljs-property">id</span> <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">set</span>.
Welcome <span class="hljs-keyword">to</span>
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   <span class="hljs-property">version</span> <span class="hljs-number">1.5</span><span class="hljs-number">.2</span>
      /_/

Using Python <span class="hljs-property">version</span> <span class="hljs-number">2.7</span><span class="hljs-number">.10</span> (default, May <span class="hljs-number">23</span> <span class="hljs-number">2015</span> <span class="hljs-number">09</span>:<span class="hljs-number">44</span>:<span class="hljs-number">00</span>)
SparkContext available <span class="hljs-keyword">as</span> sc, HiveContext available <span class="hljs-keyword">as</span> sqlContext.
&gt;&gt;&gt;
</code></pre>

<p>Enter the following lines.</p>

<p>[Source: <code>pyspark_square_numbers.py</code>]</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">square_it</span><span class="hljs-params">(num)</span>:</span>
    <span class="hljs-keyword">return</span> num * num

numbers = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>]
rdd = sc.parallelize(numbers)
squares = rdd.map(square_it)
result = squares.collect()
print(result)
</code></pre>

<p>The program produces the following output:</p>

<pre class="highlight"><code class="hljs json">[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">25</span>, <span class="hljs-number">36</span>, <span class="hljs-number">49</span>, <span class="hljs-number">64</span>, <span class="hljs-number">81</span>, <span class="hljs-number">100</span>]</code></pre>

<h3>Square Numbers Example Explained</h3>

<p>We define a function <code>square_it</code> that returns the square of a given number.
Later we are going to tell Spark to apply this function to each element of our dataset.</p>

<pre class="highlight"><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">square_it</span><span class="hljs-params">(num)</span>:</span>
    <span class="hljs-keyword">return</span> num * num</code></pre>

<p>In this example we are define and store the input list of numbers into a <code>numbers</code>
  variable.</p>

<pre class="highlight"><code class="hljs apache"><span class="hljs-keyword">numbers</span> =<span class="hljs-sqbracket"> [1,2,3,4,5,6,7,8,9,10]</span></code></pre>

<p>The list is still local in the Python's memory. We push it too Spark using the
<code>paralellize()</code> function. What Spark does in this situation is - it distributes
the data into partitions accross the cluster nodes, creating the so called resilient distributed dataset (RDD).
Spark returns a reference to the dataset which we store into a Python variable named <code>rdd</code></p>

<pre class="highlight"><code class="hljs stylus">rdd = sc.<span class="hljs-function"><span class="hljs-title">parallelize</span><span class="hljs-params">(numbers)</span></span></code></pre>

<p>We need to tell Spark to apply the <strong>square_it</strong> function to all the elements in
the <code>rdd</code> dataset. For this purpose we pass the <strong>square_it</strong> 
function reference to the <strong>map()</strong> function. The <strong>map</strong>
function creates a new dataset by applying the passed function to each element from the
  source dataset and putting the result of the function into the output dataset.</p>

<pre class="highlight"><code class="hljs python">squares = rdd.map(square_it)</code></pre>

<p>So for our result is distributed in partitions across the cluster. To actually see 
what our result is, we need to collect the partitions.</p>

<pre class="highlight"><code class="hljs python">result = squares.collect()
print(result)</code></pre>

<p>Close the console by using the <code>exit()</code> command.</p>

<h3>Submitted Execution</h3>

<p>So far we have been using the <code>pyspark</code> console to execute our program.
In practice we need to be able to run scripts without human interaction.</p>

<p>Create a Python script file <code>spark_square_numbers.py</code>.</p>

<p>[Source: <code>pyspark_square_numbers.py</code>]</p>
<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkConf, SparkContext

<span class="hljs-comment"># Configure Spark</span>
conf = SparkConf().setMaster(<span class="hljs-string">"local"</span>).setAppName(<span class="hljs-string">"SquareNumbers"</span>)

<span class="hljs-comment"># Create Spark context</span>
sc = SparkContext(conf = conf)


<span class="hljs-comment"># Define the function that will be applied to each element.</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">square_it</span><span class="hljs-params">(num)</span>:</span>
    <span class="hljs-keyword">return</span> num * num

<span class="hljs-comment"># Define our initial list of numbers</span>
numbers = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>]

<span class="hljs-comment"># Create Resilient Distributed Dataset from the numbers</span>
rdd = sc.parallelize(numbers)

<span class="hljs-comment"># Apply the square_it function (map) to each element of the RDD</span>
squares = rdd.map(square_it)

<span class="hljs-comment"># Collect the squared numbers fromthe RDD into a local list</span>
result = squares.collect()

<span class="hljs-comment"># Output the result</span>
print(result)
</code></pre>

<p>From the command line execute:</p>

<pre class="highlight"><code class="hljs elixir"><span class="hljs-variable">$ </span>spark-submit pyspark_square_numbers.py</code></pre>

<pre class="highlight"><code class="hljs vhdl">E:\SparkCourse&gt;spark-submit pyspark_square_numbers.py
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">14</span>:<span class="hljs-number">00</span>:<span class="hljs-number">46</span> WARN NativeCodeLoader: Unable <span class="hljs-keyword">to</span> load native-hadoop <span class="hljs-keyword">library</span> <span class="hljs-keyword">for</span> your platform... u
sing builtin-java classes where applicable
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">14</span>:<span class="hljs-number">00</span>:<span class="hljs-number">47</span> WARN Utils: Service <span class="hljs-attribute">'SparkUI</span>' could <span class="hljs-keyword">not</span> bind <span class="hljs-keyword">on</span> <span class="hljs-keyword">port</span> <span class="hljs-number">4040.</span> Attempting <span class="hljs-keyword">port</span> <span class="hljs-number">4041.</span>
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">14</span>:<span class="hljs-number">00</span>:<span class="hljs-number">49</span> WARN : Your hostname, Yoga resolves <span class="hljs-keyword">to</span> a loopback/non-reachable address: fe80:<span class="hljs-number">0</span>:<span class="hljs-number">0</span>:
<span class="hljs-number">0</span>:<span class="hljs-number">0</span>:<span class="hljs-number">5</span>efe:c0a8:<span class="hljs-number">9201</span>%net7, but we couldn<span class="hljs-attribute">'t</span> find any external IP address!
<span class="hljs-number">15</span>/<span class="hljs-number">11</span>/<span class="hljs-number">26</span> <span class="hljs-number">14</span>:<span class="hljs-number">00</span>:<span class="hljs-number">50</span> WARN MetricsSystem: Using <span class="hljs-keyword">default</span> name DAGScheduler <span class="hljs-keyword">for</span> source because spark.app.i
d <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> set.
[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">25</span>, <span class="hljs-number">36</span>, <span class="hljs-number">49</span>, <span class="hljs-number">64</span>, <span class="hljs-number">81</span>, <span class="hljs-number">100</span>]
</code></pre>

<h3>Further Discussion</h3>

<p>Using lambda function we can shorten our number square example into a single line.</p>

<pre class="highlight"><code class="hljs python"><span class="hljs-comment"># Square numbers version using lambda</span>
print(sc.parallelize(numbers).map(<span class="hljs-keyword">lambda</span> x: x*x).collect())</code></pre>

<p>Executing the above line in <code>pyspark</code> produces the same result.</p>

<p>Let's use our example to do some deeper exploration. We will ask Spark to 
repeat the square number excercise but each time we will pass numbers with 
different size.</p>

<pre class="highlight"><code class="hljs python"><span class="hljs-keyword">from</span> timeit <span class="hljs-keyword">import</span> default_timer <span class="hljs-keyword">as</span> timer

<span class="hljs-comment"># Define a dictionary to store execution times.</span>
<span class="hljs-comment"># { number_elements: execution_time}</span>
times = {}

<span class="hljs-comment"># Define initial number of elements</span>
number_elements = <span class="hljs-number">10</span>


<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>,<span class="hljs-number">6</span>):
    <span class="hljs-comment"># Create a list of numbers from 1 to number_elements</span>
    numbers = range(<span class="hljs-number">1</span>,number_elements+<span class="hljs-number">1</span>)
    
    <span class="hljs-comment"># Get the start time</span>
    start = timer()
    
    <span class="hljs-comment"># Execute Spark workflow</span>
    result = sc.parallelize(numbers).map(<span class="hljs-keyword">lambda</span> x: x*x).collect()
    
    <span class="hljs-comment"># Get the end time</span>
    end = timer()
    
    <span class="hljs-comment"># Save the execution time</span>
    times[number_elements] = end - start
    
    <span class="hljs-comment"># For the next iteration, set the number of elements to 10 times more</span>
    number_elements = number_elements*<span class="hljs-number">10</span>
    
<span class="hljs-keyword">import</span> collections

<span class="hljs-keyword">print</span> collections.OrderedDict(sorted(times.items()))
</code></pre>

<p>And here is the output from my laptop.</p>
<pre class="highlight"><code class="hljs gcode">OrderedDict<span class="hljs-comment">([(10, 1.2454986210296966)</span>, <span class="hljs-comment">(100, 1.216315085195049)</span>, <span class="hljs-comment">(1000, 1.260411770919461)</span>, <span class="hljs-comment">(10000, 1.2487971162436224)</span>, <span class="hljs-comment">(100000, 1.2944957938091761)</span>, <span class="hljs-comment">(1000000, 1.9364617363008279)</span>])</code></pre>

<img src="/images/posts/spark_square_times_graph.png" alt="Spark execution times graph."></div>
</article>

<footer>
<hr><small>
Posted on: Thu Nov 26 2015<br>
Tags: hadoop,bigdata,bigdata,spark,apache spark,tutorial
</small>
</footer>
		</section>
    <hr>
		<!-- Footer -->
		<footer>
			<p class="pull-left">&copy; Ivan Georgiev 2015</p>
			<p class="pull-right">
				This website was last updated on Thu Nov 26 2015
			</p>
		</footer>
	</div><!-- /container -->

	<!-- Scripts -->
	<script defer="defer"  src="/ext/jquery-1.11.3.min.js"></script><script defer="defer"  src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script><script defer="defer"  src="/ext/bootstrap/js/bootstrap.min.js"></script><script defer="defer"  src="/js/app.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69691618-2', 'auto');
  ga('send', 'pageview');
</script>    
</body>
</html>
